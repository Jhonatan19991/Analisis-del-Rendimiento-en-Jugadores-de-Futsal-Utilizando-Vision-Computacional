{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcypZrYSx0lt",
        "outputId": "33b5e684-8e79-4f0f-b565-ccff67baa2dc"
      },
      "outputs": [],
      "source": [
        "pip install ultralytics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcUM8vIWiYmo"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PX7Kg49T4-m"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8E1sR6rvwZi"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LK8QevMicaQ"
      },
      "source": [
        "# **Detecci√≥n de bal√≥n arco (resultado a color)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzQmovoUlqmY"
      },
      "source": [
        "Este c√≥digo procesa un video, detectando objetos con YOLO mientras mantiene el video a color, aunque la detecci√≥n se haga en escala de grises.\n",
        "\n",
        "**üìå En resumen:**\n",
        "\n",
        "\n",
        "*   Carga un video de entrada.\n",
        "*   Convierte cada fotograma a escala de grises para hacer la detecci√≥n.\n",
        "*   Redimensiona la imagen a 640x640 (para ajustarse al modelo YOLO).\n",
        "*   Convierte la imagen de grises a BGR antes de pasarla a YOLO.\n",
        "*   Usa YOLO para detectar objetos y obtener coordenadas de las cajas.\n",
        "*   Dibuja las cajas sobre el fotograma original en color (para que el video de salida se mantenga en color).\n",
        "*   Guarda el video con las detecciones en color.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0sCCFk8VzPs"
      },
      "outputs": [],
      "source": [
        "pip install --upgrade torch ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xaqQ2wOijlH",
        "outputId": "a02bafb7-fce1-443b-a171-f0fd5fb68267"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ‚úÖ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Intentamos configurar torch._dynamo para saltar los hooks de FSDP\n",
        "try:\n",
        "    import torch._dynamo\n",
        "    torch._dynamo.config.skip_fsdp_hooks = True\n",
        "except AttributeError:\n",
        "    print(\"No se pudo configurar torch._dynamo.config. Revisa la versi√≥n de PyTorch.\")\n",
        "\n",
        "class VideoProcessor:\n",
        "    def __init__(self, model_path):\n",
        "        # Carga del modelo personalizado\n",
        "        self.model = YOLO(model_path)\n",
        "        # Mapeo de clases: ajusta seg√∫n corresponda a tu entrenamiento\n",
        "        self.class_names = {0: \"balon\", 1: \"arco\"}\n",
        "        # Mapeo de colores en formato BGR\n",
        "        self.colors = {\n",
        "            \"bal√≥n\": (0, 0, 255),      # rojo\n",
        "            \"arco\": (255, 0, 0)   # azul\n",
        "        }\n",
        "\n",
        "    def process_video(self, input_path, output_path):\n",
        "        # Abrimos el video de entrada\n",
        "        cap = cv2.VideoCapture(input_path)\n",
        "        if not cap.isOpened():\n",
        "            raise IOError(f\"No se pudo abrir el video: {input_path}\")\n",
        "\n",
        "        # Obtenemos las propiedades del video original\n",
        "        width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        fps    = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "        # Procesamos cada fotograma del video\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            # Guardamos una copia del frame original a color\n",
        "            original_frame = frame.copy()\n",
        "\n",
        "            # Convertir a escala de grises para detecci√≥n\n",
        "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "            resized = cv2.resize(gray, (640, 640))\n",
        "\n",
        "            # Convertimos de nuevo a 3 canales para YOLO (BGR)\n",
        "            input_frame = cv2.cvtColor(resized, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "            # Hacer la detecci√≥n en la imagen en escala de grises con 3 canales\n",
        "            results = self.model(input_frame)\n",
        "\n",
        "            # Extraemos las cajas detectadas, sus coordenadas y clases\n",
        "            boxes = results[0].boxes\n",
        "            xyxy = boxes.xyxy.cpu().numpy()\n",
        "            confs = boxes.conf.cpu().numpy()\n",
        "            classes = boxes.cls.cpu().numpy()\n",
        "\n",
        "            # Calculamos el factor de escala para volver a mapear las coordenadas al tama√±o original del video\n",
        "            scale_x = width / 640\n",
        "            scale_y = height / 640\n",
        "\n",
        "            # Dibujamos las cajas de detecci√≥n en el fotograma original a color\n",
        "            for (x1, y1, x2, y2), conf, cls in zip(xyxy, confs, classes):\n",
        "                # Convertimos las coordenadas de vuelta al tama√±o original\n",
        "                x1 = int(x1 * scale_x)\n",
        "                y1 = int(y1 * scale_y)\n",
        "                x2 = int(x2 * scale_x)\n",
        "                y2 = int(y2 * scale_y)\n",
        "\n",
        "                label = self.class_names.get(int(cls), str(cls))\n",
        "                color = self.colors.get(label, (0, 255, 0))\n",
        "                cv2.rectangle(original_frame, (x1, y1), (x2, y2), color, 2)\n",
        "                cv2.putText(original_frame, f\"{label} {conf:.2f}\", (x1, y1 - 10),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "            # Escribir el fotograma procesado con detecciones en el video de salida\n",
        "            out.write(original_frame)\n",
        "\n",
        "        cap.release()\n",
        "        out.release()\n",
        "\n",
        "        return output_path\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohg3v5q7kFvg",
        "outputId": "f8f69d72-b24b-4ac1-b93b-da45543b4bbe"
      },
      "outputs": [],
      "source": [
        "processor = VideoProcessor(\"/content/best.pt\")\n",
        "video_procesado = processor.process_video(\n",
        "    input_path=r\"/content/Sample8.mp4\",\n",
        "    output_path=r\"/content/SampleFT8.mp4\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04rAFKarYdmu"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geAdL0n-YwgZ"
      },
      "source": [
        "# **Tracking bal√≥n**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß† ¬øQu√© hace este script?\n",
        "\n",
        "Este script procesa un video usando un modelo YOLO para detectar **balones** y **arcos**, y guarda un nuevo video con las detecciones visualizadas.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚öôÔ∏è Funcionamiento general\n",
        "\n",
        "- Carga un modelo YOLO entrenado previamente.\n",
        "- Procesa frame por frame:\n",
        "  - Convierte la imagen a escala de grises y la redimensiona.\n",
        "  - Realiza detecci√≥n de objetos con YOLO.\n",
        "  - Si detecta un **bal√≥n**:\n",
        "    - Dibuja la caja en el frame.\n",
        "    - Inicia un tracker CSRT.\n",
        "  - Si no lo detecta, intenta seguirlo con el tracker.\n",
        "  - Tambi√©n dibuja **arcos** si son detectados.\n",
        "- Escribe el resultado en un nuevo archivo de video.\n",
        "\n",
        "---\n",
        "\n",
        "## üè∑Ô∏è Clases utilizadas\n",
        "\n",
        "- `0`: **balon** (color rojo)\n",
        "- `1`: **arco** (color azul)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wejQVI6JYcPW"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "\n",
        "class VideoProcessor:\n",
        "    def __init__(self, model_path):\n",
        "        # Carga del modelo personalizado\n",
        "        self.model = YOLO(model_path)\n",
        "        # Mapeo de clases: ajusta seg√∫n corresponda a tu entrenamiento\n",
        "        self.class_names = {0: \"balon\", 1: \"arco\"}\n",
        "        # Mapeo de colores en formato BGR\n",
        "        self.colors = {\n",
        "            \"balon\": (0, 0, 255),      # rojo\n",
        "            \"arco\": (255, 0, 0)        # azul\n",
        "        }\n",
        "        # Tracker CSRT de OpenCV (inicialmente None)\n",
        "        self.tracker = None\n",
        "        self.last_ball_bbox = None  # [x, y, w, h] en coordenadas de frame original\n",
        "\n",
        "    def process_video(self, input_path, output_path):\n",
        "        cap = cv2.VideoCapture(input_path)\n",
        "        if not cap.isOpened():\n",
        "            raise IOError(f\"No se pudo abrir el video: {input_path}\")\n",
        "\n",
        "        width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        fps    = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            original_frame = frame.copy()\n",
        "\n",
        "            # Preprocesamiento para YOLO\n",
        "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "            resized = cv2.resize(gray, (640, 640))\n",
        "            input_frame = cv2.cvtColor(resized, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "            # Detecci√≥n con YOLO\n",
        "            results = self.model(input_frame)\n",
        "            boxes = results[0].boxes\n",
        "            xyxy = boxes.xyxy.cpu().numpy()\n",
        "            confs = boxes.conf.cpu().numpy()\n",
        "            classes = boxes.cls.cpu().numpy()\n",
        "\n",
        "            # Escala de coordenadas\n",
        "            scale_x = width / 640\n",
        "            scale_y = height / 640\n",
        "\n",
        "            # Filtramos solo la pelota (clase 0) y tomamos la de mayor confianza\n",
        "            ball_indices = [i for i, cls in enumerate(classes) if int(cls) == 0]\n",
        "            if ball_indices:\n",
        "                # Hay al menos una detecci√≥n de pelota\n",
        "                # Escogemos la de mayor confianza\n",
        "                best_i = max(ball_indices, key=lambda i: confs[i])\n",
        "                x1, y1, x2, y2 = xyxy[best_i]\n",
        "                # Convertir a coordenadas originales\n",
        "                x1, y1 = int(x1 * scale_x), int(y1 * scale_y)\n",
        "                x2, y2 = int(x2 * scale_x), int(y2 * scale_y)\n",
        "                w, h = x2 - x1, y2 - y1\n",
        "\n",
        "                # Dibujar YOLO\n",
        "                cv2.rectangle(original_frame, (x1, y1), (x2, y2), self.colors[\"balon\"], 2)\n",
        "                cv2.putText(original_frame, f\"balon {confs[best_i]:.2f}\", (x1, y1 - 10),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, self.colors[\"balon\"], 2)\n",
        "\n",
        "                # (Re)inicializar tracker CSRT con la caja detectada\n",
        "                self.tracker = cv2.TrackerCSRT_create()\n",
        "                self.last_ball_bbox = (x1, y1, w, h)\n",
        "                self.tracker.init(original_frame, self.last_ball_bbox)\n",
        "\n",
        "            else:\n",
        "                # YOLO no detect√≥ la pelota: usar tracker como respaldo\n",
        "                if self.tracker is not None:\n",
        "                    ok, bbox = self.tracker.update(original_frame)\n",
        "                    if ok:\n",
        "                        # Tracker encontr√≥ la pelota\n",
        "                        x, y, w, h = [int(v) for v in bbox]\n",
        "                        cv2.rectangle(original_frame, (x, y), (x + w, y + h), self.colors[\"balon\"], 2)\n",
        "                        cv2.putText(original_frame, \"balon (track)\", (x, y - 10),\n",
        "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, self.colors[\"balon\"], 2)\n",
        "                        self.last_ball_bbox = (x, y, w, h)\n",
        "                    else:\n",
        "                        # Tracker fall√≥: descartarlo hasta pr√≥xima detecci√≥n\n",
        "                        self.tracker = None\n",
        "                        self.last_ball_bbox = None\n",
        "\n",
        "            # Adem√°s dibujamos detecciones de \"arco\" si las hay\n",
        "            for (x1, y1, x2, y2), conf, cls in zip(xyxy, confs, classes):\n",
        "                if int(cls) == 1:  # clase \"arco\"\n",
        "                    x1, y1 = int(x1 * scale_x), int(y1 * scale_y)\n",
        "                    x2, y2 = int(x2 * scale_x), int(y2 * scale_y)\n",
        "                    cv2.rectangle(original_frame, (x1, y1), (x2, y2), self.colors[\"arco\"], 2)\n",
        "                    cv2.putText(original_frame, f\"arco {conf:.2f}\", (x1, y1 - 10),\n",
        "                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, self.colors[\"arco\"], 2)\n",
        "\n",
        "            out.write(original_frame)\n",
        "\n",
        "        cap.release()\n",
        "        out.release()\n",
        "        return output_path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNNE2z1zY47N"
      },
      "outputs": [],
      "source": [
        "processor = VideoProcessor(\"/content/best.pt\")\n",
        "video_procesado = processor.process_video(\n",
        "    input_path=r\"/content/Sample5.mp4\",\n",
        "    output_path=r\"/content/Sample5seguimiente.mp4\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xwOMAuXihnf"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wv6qrxmAgt8d"
      },
      "source": [
        "# **Cuadricula Cancha + detecci√≥n puntaje**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üé• ¬øQu√© hace este c√≥digo?\n",
        "\n",
        "Este script usa YOLO para detectar **balones** y **arcos** en un video, dibuja sobre ellos, y calcula un **puntaje** si el bal√≥n termina dentro del arco al final del video.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚öôÔ∏è Funcionamiento\n",
        "\n",
        "- Carga el modelo YOLO desde el archivo especificado.\n",
        "- Procesa frame por frame:\n",
        "  - Convierte el frame a escala de grises y lo redimensiona.\n",
        "  - Aplica YOLO para detectar objetos.\n",
        "  - Si detecta **bal√≥n**, lo dibuja y reinicia un tracker.\n",
        "  - Si no lo detecta, intenta seguirlo con el tracker.\n",
        "  - Si detecta **arco**, lo dibuja y divide en una grilla 3x3 con puntajes.\n",
        "- Guarda los frames procesados en un nuevo video.\n",
        "\n",
        "---\n",
        "\n",
        "## üßÆ Puntaje\n",
        "\n",
        "Al final del video:\n",
        "- Si hay una detecci√≥n v√°lida de bal√≥n y arco:\n",
        "  - Se calcula la celda de la grilla en la que cay√≥ el bal√≥n (seg√∫n su centro).\n",
        "  - Se asigna un puntaje (de 1 a 5) dependiendo de la celda.\n",
        "\n",
        "---\n",
        "\n",
        "## üé® Clases detectadas\n",
        "\n",
        "- `0`: **balon** (color rojo)\n",
        "- `1`: **arco** (color azul)\n",
        "\n",
        "---\n",
        "\n",
        "## üìå Resultado\n",
        "\n",
        "- Video procesado con anotaciones.\n",
        "- Se imprime el puntaje si se detect√≥ un gol.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j36G7gjxmqWc"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "\n",
        "class VideoProcessor:\n",
        "    def __init__(self, model_path):\n",
        "        self.model = YOLO(model_path)\n",
        "        self.class_names = {0: \"balon\", 1: \"arco\"}\n",
        "        self.colors = {\n",
        "            \"balon\": (0, 0, 255),  # rojo\n",
        "            \"arco\": (255, 0, 0)    # azul\n",
        "        }\n",
        "\n",
        "    def process_video(self, input_path, output_path):\n",
        "        cap = cv2.VideoCapture(input_path)\n",
        "        if not cap.isOpened():\n",
        "            raise IOError(f\"No se pudo abrir el video: {input_path}\")\n",
        "\n",
        "        width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        fps    = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "        tracker = None\n",
        "        last_ball_bbox = None\n",
        "        last_arco_bbox = None\n",
        "\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            original_frame = frame.copy()\n",
        "\n",
        "            # Preprocesamiento para YOLO\n",
        "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "            resized = cv2.resize(gray, (640, 640))\n",
        "            input_frame = cv2.cvtColor(resized, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "            results = self.model(input_frame)\n",
        "            boxes = results[0].boxes\n",
        "            xyxy = boxes.xyxy.cpu().numpy()\n",
        "            confs = boxes.conf.cpu().numpy()\n",
        "            classes = boxes.cls.cpu().numpy()\n",
        "\n",
        "            scale_x = width / 640\n",
        "            scale_y = height / 640\n",
        "\n",
        "            # 1) Detectar bal√≥n (mejor confianza)\n",
        "            ball_indices = [i for i, cls in enumerate(classes) if int(cls) == 0]\n",
        "            if ball_indices:\n",
        "                best_i = max(ball_indices, key=lambda i: confs[i])\n",
        "                x1, y1, x2, y2 = xyxy[best_i]\n",
        "                x1, y1 = int(x1 * scale_x), int(y1 * scale_y)\n",
        "                x2, y2 = int(x2 * scale_x), int(y2 * scale_y)\n",
        "                w, h = x2 - x1, y2 - y1\n",
        "\n",
        "                cv2.rectangle(original_frame, (x1, y1), (x2, y2), self.colors[\"balon\"], 2)\n",
        "                cv2.putText(original_frame, f\"balon {confs[best_i]:.2f}\", (x1, y1 - 10),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, self.colors[\"balon\"], 2)\n",
        "\n",
        "                # reiniciar tracker\n",
        "                tracker = cv2.TrackerCSRT_create()\n",
        "                tracker.init(original_frame, (x1, y1, w, h))\n",
        "                last_ball_bbox = (x1, y1, w, h)\n",
        "            else:\n",
        "                # tracking si no detecta\n",
        "                if tracker is not None:\n",
        "                    ok, bbox = tracker.update(original_frame)\n",
        "                    if ok:\n",
        "                        x, y, w, h = [int(v) for v in bbox]\n",
        "                        cv2.rectangle(original_frame, (x, y), (x + w, y + h), self.colors[\"balon\"], 2)\n",
        "                        cv2.putText(original_frame, \"balon (track)\", (x, y - 10),\n",
        "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, self.colors[\"balon\"], 2)\n",
        "                        last_ball_bbox = (x, y, w, h)\n",
        "                    else:\n",
        "                        tracker = None\n",
        "\n",
        "            # 2) Detectar arco (podr√≠a haber m√∫ltiples, tomamos el de mayor confianza)\n",
        "            arco_indices = [i for i, cls in enumerate(classes) if int(cls) == 1]\n",
        "            if arco_indices:\n",
        "                best_j = max(arco_indices, key=lambda i: confs[i])\n",
        "                ax1, ay1, ax2, ay2 = xyxy[best_j]\n",
        "                ax1, ay1 = int(ax1 * scale_x), int(ay1 * scale_y)\n",
        "                ax2, ay2 = int(ax2 * scale_x), int(ay2 * scale_y)\n",
        "\n",
        "                cv2.rectangle(original_frame, (ax1, ay1), (ax2, ay2), self.colors[\"arco\"], 2)\n",
        "                cv2.putText(original_frame, f\"arco {confs[best_j]:.2f}\", (ax1, ay1 - 10),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, self.colors[\"arco\"], 2)\n",
        "\n",
        "                last_arco_bbox = (ax1, ay1, ax2, ay2)\n",
        "\n",
        "                # dibujar cuadricula (para visual)\n",
        "                cell_w = (ax2 - ax1) // 3\n",
        "                cell_h = (ay2 - ay1) // 3\n",
        "                puntajes = [[5, 2, 5],\n",
        "                            [3, 1, 3],\n",
        "                            [5, 1, 5]]\n",
        "                for i in range(3):\n",
        "                    for j in range(3):\n",
        "                        cx1 = ax1 + j * cell_w\n",
        "                        cy1 = ay1 + i * cell_h\n",
        "                        cx2 = cx1 + cell_w\n",
        "                        cy2 = cy1 + cell_h\n",
        "                        cv2.rectangle(original_frame, (cx1, cy1), (cx2, cy2), (0, 255, 0), 1)\n",
        "                        cv2.putText(original_frame, str(puntajes[i][j]), (cx1 + 5, cy1 + 20),\n",
        "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
        "\n",
        "            out.write(original_frame)\n",
        "\n",
        "        cap.release()\n",
        "        out.release()\n",
        "\n",
        "        # 3) Al final, calcular puntaje si hubo bal√≥n y arco\n",
        "        puntaje_asignado = None\n",
        "        if last_ball_bbox and last_arco_bbox:\n",
        "            bx, by, bw, bh = last_ball_bbox\n",
        "            ball_cx = bx + bw // 2\n",
        "            ball_cy = by + bh // 2\n",
        "\n",
        "            ax1, ay1, ax2, ay2 = last_arco_bbox\n",
        "            if ax1 <= ball_cx <= ax2 and ay1 <= ball_cy <= ay2:\n",
        "                cell_w = (ax2 - ax1) // 3\n",
        "                cell_h = (ay2 - ay1) // 3\n",
        "                puntajes = [[5, 2, 5],\n",
        "                            [3, 1, 3],\n",
        "                            [5, 1, 5]]\n",
        "                col = int(min(max((ball_cx - ax1) // cell_w, 0), 2))\n",
        "                row = int(min(max((ball_cy - ay1) // cell_h, 0), 2))\n",
        "                puntaje_asignado = puntajes[row][col]\n",
        "\n",
        "        if puntaje_asignado is not None:\n",
        "            print(f\"Puntaje asignado: {puntaje_asignado}\")\n",
        "        else:\n",
        "            print(\"No se detect√≥ un gol en el video.\")\n",
        "\n",
        "        return output_path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zq4bvtD-kfaW",
        "outputId": "5476408f-02b3-4124-f0af-a8f7d6784d31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Puntaje asignado: 5\n"
          ]
        }
      ],
      "source": [
        "processor = VideoProcessor(\"/content/best.pt\")\n",
        "video_procesado = processor.process_video(\n",
        "    input_path=r\"/content/Sample3-recortado.mp4\",\n",
        "    output_path=r\"/content/Sample3Gol.mp4\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8R7J4wdMcize"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
